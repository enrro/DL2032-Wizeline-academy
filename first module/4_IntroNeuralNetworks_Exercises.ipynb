{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "During this session, you will participate in a supervised learning exercise about digit recognition. You will:\n",
    "- Build a neural network.\n",
    "- Train your neural network with a dataset that contains images that represent numbers. \n",
    "- Modify the architecture of the neural network to obtain better results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The MNIST data\n",
    "\n",
    "\n",
    "The MNIST data is comprised of pictures that represent a number and includes the number label associated to each picture. The data set is split into three data parts:\n",
    "- training (mnist.train)\n",
    "- testing (mnist.test)\n",
    "- validation (mnist.validation)\n",
    "\n",
    "The validation split is important because it's essential in machine learning that there is separate data which is not given to the machine during the learning phase. After the initial machine learning session, you present the separate data to the machine and assess the performance of it. The test and validation sets may serve different evaluation purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "mnist = input_data.read_data_sets(\"./Data/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating the model\n",
    "\n",
    "Common numerical computing libraries in Python use external code that is implemented in other languages to take advantage of their efficiency. However, switching back to Python for every operation causes overhead. This overhead is bad if you want to run computations on GPUs or in a distributed manner since there is a high cost to transfer data.\n",
    "\n",
    "TensorFlow does its heavy lifting outside of Python. Although it does not run expensive operations independently from Python, TensorFlow enables you to describe a graph of interacting operations that run entirely outside Python.\n",
    "\n",
    "#### TensorFlow Graph\n",
    "Create a TensorFlow graph that represents a neural network with no hidden layers and an output layer comprised of 10 nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Write your code here\n",
    "########################\n",
    "image_size = 28*28\n",
    "number_digits = 10\n",
    "next_layer_neurons = 10\n",
    "\n",
    "# Placeholders to build the graph\n",
    "x = tf.placeholder(tf.float32, [None, image_size])\n",
    "y_ = tf.placeholder(tf.float32, [None, number_digits])\n",
    "\n",
    "#initialize weights and bias to zeroes\n",
    "W = tf.Variable(tf.zeros([image_size, next_layer_neurons]))\n",
    "b = tf.Variable(tf.zeros([next_layer_neurons]))\n",
    "\n",
    "# Matrix multiplication\n",
    "y = tf.matmul(x, W) + b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining Cost Funtion and Optimizer\n",
    "\n",
    "In order to train the model, define what it means to improve the results after each iteration. Use a cost function and try to minimize with respect to it. The cost function represents how far you are from our desired outcome. Minimizing the error leads you towards improving the model.\n",
    "\n",
    "A common cost function is called *cross-entropy*. Cross-entropy takes advantage of large errors and reduces the learning slow down that is caused because of traditional cost functions (i.e. quadratic cost function). In summary, it will take less to train a good model.\n",
    "\n",
    "#### TensorFlow\n",
    "1. Create a tensor to represent the cross-entropy function. \n",
    "1. Create a tensor to represent a Gradient Descent Optimizer that minimizes the cross-entropy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Write your code here\n",
    "########################\n",
    "\n",
    "cross_entropy = tf.reduce_mean(\n",
    "    tf.nn.softmax_cross_entropy_with_logits(labels= y_, logits=y))\n",
    "\n",
    "learn_rate = 0.5\n",
    "train_step = tf.train.GradientDescentOptimizer(\n",
    "                learning_rate = learn_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a TensorFlow Session\n",
    "\n",
    "You have defined your model by creating a complete Tensorflow graph. Now, you need to launch it. Create an interactive session and initialize all the variables defined before.\n",
    "\n",
    "#### Interactive Session\n",
    "Create an Interactive Session and run the global variable initializer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Write your code here\n",
    "########################\n",
    "\n",
    "# a session allows to run the neural network\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "#Initialize memory for the architecture variables\n",
    "\n",
    "tf.global_variables_initializer().run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train\n",
    "\n",
    "MNIST is a large dataset. To train using a batch learning method is too time intensive in-between epochs. Therefore, use small batches of random data. This method is called stochastic training.\n",
    "\n",
    "#### Stochastic Training\n",
    "1. In a `for` loop, take 100 random samples from MNIST and run the train step using the resulting batches. \n",
    "1. Repeat the process as many times as necessary. \n",
    "1. Present all the training datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################\n",
    "# Write your code here\n",
    "########################\n",
    "\n",
    "# Create batches of information\n",
    "iterations = 55\n",
    "batch_size = 1000\n",
    "\n",
    "# Feed the batches\n",
    "for _ in range(iterations):\n",
    "    batch_xs, batch_ys = mnist.train.next_batch(batch_size)\n",
    "    sess.run(train_step,\n",
    "            feed_dict={x: batch_xs, y_: batch_ys})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate your model\n",
    "\n",
    "To understand your model's precision, you need to compare your results with the expected output. To calculate the precision, you need to sum the correct classifications over the size of the testing dataset.\n",
    "#### Calculating Precision\n",
    "1. Create a Tensor that compares the model's output with the expected output. \n",
    "1. Determine the fraction that are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9022\n"
     ]
    }
   ],
   "source": [
    "########################\n",
    "# Write your code here\n",
    "########################\n",
    "#compare if the prediction matches reality\n",
    "# Compare if the prediction matches reality\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1),\n",
    "                              tf.argmax(y_, 1))\n",
    "\n",
    "# Compute accuracy based on a binary result\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction,\n",
    "                                  tf.float32))\n",
    "\n",
    "# Print the value of accuracy (Notice the TEST dataset)\n",
    "print(sess.run(accuracy, feed_dict={x:mnist.test.images,\n",
    "                                    y_:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create your own Neural Network\n",
    "**Goal:** Train a neural network (NN) with accuracy of ~95% on the testing set.\n",
    "#### Steps:\n",
    "* Create a NN with 2 hidden layers and 300 nodes in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Control Variables\n",
    "\n",
    "\n",
    "\n",
    "#Placeholders to build the graph\n",
    "\n",
    "\n",
    "\n",
    "#First Layer - Initialize weights and bias, \n",
    "#First Layer - Sigmoid matrix multiplication\n",
    "\n",
    "\n",
    "\n",
    "#Second Layer - Initialize weights and bias\n",
    "#Second Layer - Sigmoid matrix multiplication\n",
    "\n",
    "\n",
    "\n",
    "#Output Layer - Initialize weights and bias\n",
    "#Output Layer - Matrix multiplication\n",
    "\n",
    "\n",
    "#Softmax is one of many cost functions\n",
    "\n",
    "\n",
    "#Gradient Descent is one of many cost-function optimizers\n",
    "\n",
    "\n",
    "#A session allows to run the neural network.\n",
    "\n",
    "\n",
    "#Initialize memory for the architecture variables\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Train model with 10 epochs.\n",
    "* Print the accuracy at each epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create epochs and batches of information\n",
    "\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #Feed the batches\n",
    "    \n",
    "\n",
    "    #Compare if the prediction matches reality\n",
    "\n",
    "    #Compute accuracy based on binary result\n",
    "\n",
    "    #Print the value of accuracy (Notice the TEST dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "* Print the final accuracy of the training set.\n",
    "* Print the final accuracy of the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Compare if the prediction matches reality\n",
    "\n",
    "\n",
    "#Compute accuracy based on binary result\n",
    "\n",
    "\n",
    "#Print the value of accuracy (Notice the TRAIN dataset)\n",
    "\n",
    "\n",
    "#Print the value of accuracy (Notice the TEST dataset)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "During the exercise you:\n",
    "- Learned how to create a neural network and train it. \n",
    "- Tested the performance of your model, and found that the network architecture definition is important to obtain better results.\n",
    "- Learned the importance of the initialization step (random numbers instead of zeroes), and how it impacts performance. \n",
    "- Reviewed the activation functionsâ€™ impact in performance.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
