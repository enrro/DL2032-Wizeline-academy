# Notas de clase
## Partes de un perceptron
* funcion de activacion
* bias.
* weight

porque una red neuronal puede resolver problemas no lineales?
	porque conmbina multiples lineas
	cada perceptron hace una linea.

requisitos de una red neuronal
diferenciable funcion de activacion no lineal.
capas ocultas entre el input y output.
gran grado de conectividad.

tensorflow es para poder hacer estructuras de redes neuronales.

las capas ocultas nos dan la no linearidad de la red.

aprendemos por medio de neuronas, errores, feedback

para poder mejorar las redes neuronales tienes que saber la pendiente, la derivada de la funcion de costos y el tama√±o del paso (define learning rate).



## gradient descent

1. initialize weights
2. define learning rate
3. optain gradient
4. update weights
5. repeat

## backpropagation

### forwardpass

epoc. cuando se termina de recorrer todo el dataset una vez 

ocho@wizeline.com
se pueden solicitar hangouts.
